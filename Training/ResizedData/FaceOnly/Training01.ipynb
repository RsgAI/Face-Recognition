{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training1\n",
    "\n",
    "In this notebook file, ResizedData-FaceOnly dataset will be read from pkl file.\n",
    "\n",
    "Input(X) and Output(Y) numpy arrays will be created from pandas dataframes.\n",
    "\n",
    "A deep learning model based on VGG16 architecture will be created.\n",
    "\n",
    "A keras utils Sequence class will be defined so that operations can be performed on the data to be used during the training.\n",
    "\n",
    "Performance will be checked with Validation data while training model with Training data.\n",
    "\n",
    "Accuracy and Loss charts will be drawn according to epoch numbers.\n",
    "\n",
    "The results obtained by evaluating the model with Test data will be printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries are being imported\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy Version: 1.22.3\n",
      "pandas Version: 1.4.3\n",
      "tensorflow Version: 2.6.0\n",
      "matplotlib Version: 3.5.2\n"
     ]
    }
   ],
   "source": [
    "#Library versions are being printed\n",
    "print('numpy Version: ' + np.__version__)\n",
    "print('pandas Version: ' + pd.__version__)\n",
    "print('tensorflow Version: ' + tf.__version__)\n",
    "print('matplotlib Version: ' + matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "#GPU will be used for training\n",
    "myGPU = tf.test.gpu_device_name()\n",
    "if myGPU:\n",
    "    print(myGPU)\n",
    "else:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abdullah Gul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adrien Brody</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ahmed Chalabi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ai Sugiyama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alan Greenspan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>Yasser Arafat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>Yoko Ono</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>Yoriko Kawaguchi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>Zhu Rongji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>Zinedine Zidane</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>423 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name\n",
       "ID                   \n",
       "0        Abdullah Gul\n",
       "1        Adrien Brody\n",
       "2       Ahmed Chalabi\n",
       "3         Ai Sugiyama\n",
       "4      Alan Greenspan\n",
       "..                ...\n",
       "418     Yasser Arafat\n",
       "419          Yoko Ono\n",
       "420  Yoriko Kawaguchi\n",
       "421        Zhu Rongji\n",
       "422   Zinedine Zidane\n",
       "\n",
       "[423 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Person dataframe in ResizeData is being read from md5 file\n",
    "personDf = pd.read_pickle(\"../../../Data/ResizedData/Person.pkl\")\n",
    "personDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PersonID</th>\n",
       "      <th>ImageBGR</th>\n",
       "      <th>DetectionType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>[[[71, 116, 99], [69, 116, 98], [67, 115, 98],...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125</td>\n",
       "      <td>[[[10, 24, 36], [12, 26, 38], [18, 32, 44], [2...</td>\n",
       "      <td>NoFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>356</td>\n",
       "      <td>[[[177, 199, 204], [176, 199, 204], [175, 200,...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>277</td>\n",
       "      <td>[[[91, 103, 121], [91, 104, 122], [92, 105, 12...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>131</td>\n",
       "      <td>[[[42, 65, 81], [38, 61, 77], [30, 53, 68], [2...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4151</th>\n",
       "      <td>4</td>\n",
       "      <td>[[[64, 89, 93], [62, 88, 92], [60, 86, 90], [5...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>120</td>\n",
       "      <td>[[[114, 93, 71], [116, 96, 74], [122, 101, 79]...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4153</th>\n",
       "      <td>322</td>\n",
       "      <td>[[[197, 207, 207], [196, 208, 210], [195, 207,...</td>\n",
       "      <td>NoFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4154</th>\n",
       "      <td>383</td>\n",
       "      <td>[[[7, 5, 5], [7, 5, 5], [8, 5, 5], [8, 6, 6], ...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4155</th>\n",
       "      <td>44</td>\n",
       "      <td>[[[6, 4, 4], [6, 4, 4], [5, 5, 5], [5, 5, 5], ...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4156 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PersonID                                           ImageBGR  \\\n",
       "0           22  [[[71, 116, 99], [69, 116, 98], [67, 115, 98],...   \n",
       "1          125  [[[10, 24, 36], [12, 26, 38], [18, 32, 44], [2...   \n",
       "2          356  [[[177, 199, 204], [176, 199, 204], [175, 200,...   \n",
       "3          277  [[[91, 103, 121], [91, 104, 122], [92, 105, 12...   \n",
       "4          131  [[[42, 65, 81], [38, 61, 77], [30, 53, 68], [2...   \n",
       "...        ...                                                ...   \n",
       "4151         4  [[[64, 89, 93], [62, 88, 92], [60, 86, 90], [5...   \n",
       "4152       120  [[[114, 93, 71], [116, 96, 74], [122, 101, 79]...   \n",
       "4153       322  [[[197, 207, 207], [196, 208, 210], [195, 207,...   \n",
       "4154       383  [[[7, 5, 5], [7, 5, 5], [8, 5, 5], [8, 6, 6], ...   \n",
       "4155        44  [[[6, 4, 4], [6, 4, 4], [5, 5, 5], [5, 5, 5], ...   \n",
       "\n",
       "     DetectionType  \n",
       "0       SingleFace  \n",
       "1           NoFace  \n",
       "2       SingleFace  \n",
       "3       SingleFace  \n",
       "4       SingleFace  \n",
       "...            ...  \n",
       "4151    SingleFace  \n",
       "4152    SingleFace  \n",
       "4153        NoFace  \n",
       "4154    SingleFace  \n",
       "4155    SingleFace  \n",
       "\n",
       "[4156 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FaceOnly Training data is being read from md5 file\n",
    "trainingDf = pd.read_pickle(\"../../../Data/ResizedData/FaceOnly/Training.pkl\")\n",
    "trainingDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4156, 224, 224, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trainingX is being extracted from trainingDf as wanted shape\n",
    "#trainingX contains images with pixel values of data type np.uint8 in the range [0, 255]\n",
    "\n",
    "#Many pre-trained models, including the ones to be used within the scope of this project,\n",
    "#have been trained with images containing pixel values in the [-1, 1] range\n",
    "#In this way, the data will be symmetrical and the performance of the Backpropagation algorithm will be increased\n",
    "#See https://en.wikipedia.org/wiki/Backpropagation\n",
    "#See also https://stackoverflow.com/questions/59540276/why-in-preprocessing-image-data-we-need-to-do-zero-centered-data\n",
    "#Therefore, training will be performed by converting pixel values to this range with the simplest method (pixel / 127.5 - 1)\n",
    "\n",
    "#Converting pixel values to range [-1, 1] in this section is an option\n",
    "#Doing this once over the entire array now will be save time\n",
    "#This is not how the conversion will be done because of some memory problems in this project\n",
    "#Images are of data type np.uint8 when they are in the range [0, 255]\n",
    "#np.uint8 requires 1 byte memory while np.float32 requires 4 byte and np.float64 requires 8 byte\n",
    "#See https://www.educba.com/numpy-data-types/\n",
    "#When np.uint8 data type, images use about 1GB memory\n",
    "#Even if these pixel values are converted to np.float32 data type, it will need about 4GB of memory\n",
    "#The computer used for this project has 8GB Ram\n",
    "#Considering operating system requirements, memory required by the model, etc. 8GB Ram is not enough for this process\n",
    "#For this reason, this method is not preferred, although it will save time\n",
    "\n",
    "trainingX = np.array(trainingDf.ImageBGR.values.tolist())\n",
    "trainingX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4156, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trainingY is being extracted from trainingDf as wanted shape\n",
    "trainingY = np.array(trainingDf.PersonID.values.tolist()).reshape((-1,1))\n",
    "trainingY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PersonID</th>\n",
       "      <th>ImageBGR</th>\n",
       "      <th>DetectionType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171</td>\n",
       "      <td>[[[64, 65, 56], [93, 94, 85], [143, 144, 135],...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120</td>\n",
       "      <td>[[[102, 116, 110], [106, 120, 114], [115, 129,...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>196</td>\n",
       "      <td>[[[23, 40, 43], [23, 40, 43], [24, 41, 44], [2...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95</td>\n",
       "      <td>[[[34, 55, 63], [35, 56, 65], [38, 59, 69], [4...</td>\n",
       "      <td>MultipleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>380</td>\n",
       "      <td>[[[227, 227, 227], [227, 227, 227], [227, 227,...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>71</td>\n",
       "      <td>[[[104, 116, 120], [103, 116, 121], [102, 117,...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>183</td>\n",
       "      <td>[[[35, 17, 10], [35, 17, 11], [36, 17, 12], [3...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>120</td>\n",
       "      <td>[[[109, 141, 160], [105, 137, 156], [97, 129, ...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>120</td>\n",
       "      <td>[[[84, 94, 111], [81, 91, 108], [76, 86, 103],...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>209</td>\n",
       "      <td>[[[59, 64, 65], [57, 61, 62], [53, 57, 58], [5...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>914 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PersonID                                           ImageBGR DetectionType\n",
       "0         171  [[[64, 65, 56], [93, 94, 85], [143, 144, 135],...    SingleFace\n",
       "1         120  [[[102, 116, 110], [106, 120, 114], [115, 129,...    SingleFace\n",
       "2         196  [[[23, 40, 43], [23, 40, 43], [24, 41, 44], [2...    SingleFace\n",
       "3          95  [[[34, 55, 63], [35, 56, 65], [38, 59, 69], [4...  MultipleFace\n",
       "4         380  [[[227, 227, 227], [227, 227, 227], [227, 227,...    SingleFace\n",
       "..        ...                                                ...           ...\n",
       "909        71  [[[104, 116, 120], [103, 116, 121], [102, 117,...    SingleFace\n",
       "910       183  [[[35, 17, 10], [35, 17, 11], [36, 17, 12], [3...    SingleFace\n",
       "911       120  [[[109, 141, 160], [105, 137, 156], [97, 129, ...    SingleFace\n",
       "912       120  [[[84, 94, 111], [81, 91, 108], [76, 86, 103],...    SingleFace\n",
       "913       209  [[[59, 64, 65], [57, 61, 62], [53, 57, 58], [5...    SingleFace\n",
       "\n",
       "[914 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FaceOnly Validation data is being read from md5 file\n",
    "validationDf = pd.read_pickle(\"../../../Data/ResizedData/FaceOnly/Validation.pkl\")\n",
    "validationDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(914, 224, 224, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validationX is being extracted from validationDf as wanted shape\n",
    "#validationX contains images with pixel values of data type np.uint8 in the range [0, 255]\n",
    "\n",
    "#Many pre-trained models, including the ones to be used within the scope of this project,\n",
    "#have been trained with images containing pixel values in the [-1, 1] range\n",
    "#In this way, the data will be symmetrical and the performance of the Backpropagation algorithm will be increased\n",
    "#See https://en.wikipedia.org/wiki/Backpropagation\n",
    "#See also https://stackoverflow.com/questions/59540276/why-in-preprocessing-image-data-we-need-to-do-zero-centered-data\n",
    "#Therefore, training will be performed by converting pixel values to this range with the simplest method (pixel / 127.5 - 1)\n",
    "\n",
    "#Converting pixel values to range [-1, 1] in this section is an option\n",
    "#Doing this once over the entire array now will be save time\n",
    "#This is not how the conversion will be done because of some memory problems in this project\n",
    "#Images are of data type np.uint8 when they are in the range [0, 255]\n",
    "#np.uint8 requires 1 byte memory while np.float32 requires 4 byte and np.float64 requires 8 byte\n",
    "#See https://www.educba.com/numpy-data-types/\n",
    "#When np.uint8 data type, images use about 1GB memory\n",
    "#Even if these pixel values are converted to np.float32 data type, it will need about 4GB of memory\n",
    "#The computer used for this project has 8GB Ram\n",
    "#Considering operating system requirements, memory required by the model, etc. 8GB Ram is not enough for this process\n",
    "#For this reason, this method is not preferred, although it will save time\n",
    "\n",
    "validationX = np.array(validationDf.ImageBGR.values.tolist())\n",
    "validationX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(914, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validationY is being extracted from validationDf as wanted shape\n",
    "validationY = np.array(validationDf.PersonID.values.tolist()).reshape((-1,1))\n",
    "validationY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              25691136  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 423)               433575    \n",
      "=================================================================\n",
      "Total params: 41,888,999\n",
      "Trainable params: 41,888,999\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#sequential model is being created\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#input layer\n",
    "model.add(tf.keras.layers.Input(shape = trainingX[0].shape))\n",
    "\n",
    "#First Block\n",
    "model.add(tf.keras.layers.Conv2D(64, 3, activation = 'relu', padding = \"same\"))\n",
    "model.add(tf.keras.layers.Conv2D(64, 3, activation = 'relu', padding = \"same\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(2, padding = \"valid\"))\n",
    "\n",
    "#Second Block\n",
    "model.add(tf.keras.layers.Conv2D(128, 3, activation = 'relu', padding = \"same\"))\n",
    "model.add(tf.keras.layers.Conv2D(128, 3, activation = 'relu', padding = \"same\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(2, padding = \"valid\"))\n",
    "\n",
    "#Third Block\n",
    "model.add(tf.keras.layers.Conv2D(256, 3, activation = 'relu', padding = \"same\"))\n",
    "model.add(tf.keras.layers.Conv2D(256, 3, activation = 'relu', padding = \"same\"))\n",
    "model.add(tf.keras.layers.Conv2D(256, 3, activation = 'relu', padding = \"same\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(2, padding = \"valid\"))\n",
    "\n",
    "#Fifth Block\n",
    "model.add(tf.keras.layers.Conv2D(512, 3, activation = 'relu', padding = \"same\"))\n",
    "model.add(tf.keras.layers.Conv2D(512, 3, activation = 'relu', padding = \"same\"))\n",
    "model.add(tf.keras.layers.Conv2D(512, 3, activation = 'relu', padding = \"same\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(2, padding = \"valid\"))\n",
    "\n",
    "#Sixth Block\n",
    "model.add(tf.keras.layers.Conv2D(512, 3, activation = 'relu', padding = \"same\"))\n",
    "model.add(tf.keras.layers.Conv2D(512, 3, activation = 'relu', padding = \"same\"))\n",
    "model.add(tf.keras.layers.Conv2D(512, 3, activation = 'relu', padding = \"same\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(2, padding = \"valid\"))\n",
    "\n",
    "#Flatten Layer\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "#Fully Connected Layer\n",
    "model.add(tf.keras.layers.Dense(1024, activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(1024, activation = 'relu'))\n",
    "\n",
    "#Dropout Layer for prevent overfitting\n",
    "#See https://en.wikipedia.org/wiki/Overfitting\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "#Output Layer\n",
    "model.add(tf.keras.layers.Dense(personDf.shape[0], activation = tf.nn.softmax))\n",
    "\n",
    "#summary of model is being printed\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model is being compiled with Adam optimizer\n",
    "#Adam optimizer is a common used optimizer\n",
    "#See https://keras.io/api/optimizers/adam/\n",
    "#See also https://towardsdatascience.com/7-tips-to-choose-the-best-optimizer-47bb9c1219e\n",
    "#SparseCategoricalCrossentropy loss function is being used because of the label format of the data\n",
    "#SparseCategoricalAccuracy is being used as metric because of the label format of the data\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name = 'accuracy')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A class inherited from keras utils Sequence is being created\n",
    "class FitSequence(tf.keras.utils.Sequence):\n",
    "    \n",
    "    #Constructor method is being defined\n",
    "    def __init__(self, image, label, batchSize):\n",
    "        self.image, self.label = image, label\n",
    "        self.batchSize = batchSize\n",
    "        \n",
    "        #A numpy array for image indexes is being created\n",
    "        #This array will be used to shuffle the data\n",
    "        self.index = np.arange(self.image.shape[0])\n",
    "    \n",
    "    #__len__ method is being defined\n",
    "    #This method will be used by the model to show the amount of progress of each epoch\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.image.shape[0] / float(self.batchSize)))\n",
    "    \n",
    "    #__getitem__ method is being defined\n",
    "    #The model will retrieve the batches it will use during training by calling this method\n",
    "    #With this method, the data to be used by the model can be manipulated\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        #When the model requests data, the next batch size will be selected based on index array\n",
    "        indexPart = self.index[idx * self.batchSize : (idx + 1) * self.batchSize]\n",
    "        \n",
    "        #Before being sent to the model on demand pixel values will be converted to range [-1, 1]\n",
    "        #Doing this operation here means that it will be repeated as many epochs for each image and this wastes time\n",
    "        #This is how the conversion is being done because of some memory problem in this project\n",
    "        batchX = (self.image[indexPart] / 127.5) - 1\n",
    "        batchY = self.label[indexPart]\n",
    "        return np.array(batchX), np.array(batchY)\n",
    "    \n",
    "    #on_epoch_end method is being defined\n",
    "    #The model will call this method after each epoch is ended\n",
    "    def on_epoch_end(self):\n",
    "        \n",
    "        #At the end of the epoch, the index array is being shuffled \n",
    "        #so that the data in the next epoch is returned in different orders\n",
    "        np.random.shuffle(self.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "520/520 [==============================] - 699s 1s/step - loss: 5.6685 - accuracy: 0.0801 - val_loss: 5.3324 - val_accuracy: 0.0952\n",
      "Epoch 2/20\n",
      "520/520 [==============================] - 680s 1s/step - loss: 5.5149 - accuracy: 0.0852 - val_loss: 5.3144 - val_accuracy: 0.0952\n",
      "Epoch 3/20\n",
      "520/520 [==============================] - 722s 1s/step - loss: 5.5016 - accuracy: 0.0852 - val_loss: 5.3151 - val_accuracy: 0.0952\n",
      "Epoch 4/20\n",
      "520/520 [==============================] - 750s 1s/step - loss: 5.4996 - accuracy: 0.0852 - val_loss: 5.3360 - val_accuracy: 0.0952\n",
      "Epoch 5/20\n",
      "520/520 [==============================] - 708s 1s/step - loss: 5.4991 - accuracy: 0.0852 - val_loss: 5.3103 - val_accuracy: 0.0952\n",
      "Epoch 6/20\n",
      "520/520 [==============================] - 702s 1s/step - loss: 5.4969 - accuracy: 0.0852 - val_loss: 5.3124 - val_accuracy: 0.0952\n",
      "Epoch 7/20\n",
      "520/520 [==============================] - 653s 1s/step - loss: 5.4962 - accuracy: 0.0852 - val_loss: 5.3131 - val_accuracy: 0.0952\n",
      "Epoch 8/20\n",
      "520/520 [==============================] - 688s 1s/step - loss: 5.4927 - accuracy: 0.0852 - val_loss: 5.3094 - val_accuracy: 0.0952\n",
      "Epoch 9/20\n",
      "520/520 [==============================] - 651s 1s/step - loss: 5.4907 - accuracy: 0.0852 - val_loss: 5.3274 - val_accuracy: 0.0952\n",
      "Epoch 10/20\n",
      "520/520 [==============================] - 665s 1s/step - loss: 5.4915 - accuracy: 0.0852 - val_loss: 5.3141 - val_accuracy: 0.0952\n",
      "Epoch 11/20\n",
      "520/520 [==============================] - 653s 1s/step - loss: 5.4923 - accuracy: 0.0852 - val_loss: 5.3115 - val_accuracy: 0.0952\n",
      "Epoch 12/20\n",
      "520/520 [==============================] - 667s 1s/step - loss: 5.4889 - accuracy: 0.0852 - val_loss: 5.3158 - val_accuracy: 0.0952\n",
      "Epoch 13/20\n",
      "520/520 [==============================] - 734s 1s/step - loss: 5.4891 - accuracy: 0.0852 - val_loss: 5.3200 - val_accuracy: 0.0952\n",
      "Epoch 14/20\n",
      "520/520 [==============================] - 742s 1s/step - loss: 5.4874 - accuracy: 0.0852 - val_loss: 5.3145 - val_accuracy: 0.0952\n",
      "Epoch 15/20\n",
      "520/520 [==============================] - 699s 1s/step - loss: 5.4873 - accuracy: 0.0852 - val_loss: 5.3106 - val_accuracy: 0.0952\n",
      "Epoch 16/20\n",
      "520/520 [==============================] - 705s 1s/step - loss: 5.4870 - accuracy: 0.0852 - val_loss: 5.3074 - val_accuracy: 0.0952\n",
      "Epoch 17/20\n",
      "520/520 [==============================] - 664s 1s/step - loss: 5.4851 - accuracy: 0.0852 - val_loss: 5.3271 - val_accuracy: 0.0952\n",
      "Epoch 18/20\n",
      "520/520 [==============================] - 757s 1s/step - loss: 5.4873 - accuracy: 0.0852 - val_loss: 5.3149 - val_accuracy: 0.0952\n",
      "Epoch 19/20\n",
      "520/520 [==============================] - 645s 1s/step - loss: 5.4846 - accuracy: 0.0852 - val_loss: 5.3191 - val_accuracy: 0.0952\n",
      "Epoch 20/20\n",
      "520/520 [==============================] - 653s 1s/step - loss: 5.4848 - accuracy: 0.0852 - val_loss: 5.3100 - val_accuracy: 0.0952\n"
     ]
    }
   ],
   "source": [
    "#model is being trained with 20 epochs and 8 batchSize using GPU\n",
    "#A small batchSize value is being chosen to prevent GPU memory problem\n",
    "#Large batchSize reduce training time while also generally providing better results\n",
    "with tf.device(myGPU):\n",
    "    trainingHistory = model.fit(\n",
    "        FitSequence(trainingX, trainingY, 8),\n",
    "        epochs = 20,\n",
    "        validation_data = FitSequence(validationX, validationY, 8)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Loss Chart is being drawn\n",
    "\n",
    "#Chart Values\n",
    "plt.plot(trainingHistory.history['loss'])\n",
    "plt.plot(trainingHistory.history['val_loss'])\n",
    "\n",
    "#Chart Tittle\n",
    "plt.title('Model Loss Chart')\n",
    "\n",
    "#Chart Labels\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "#Chart Lines\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "\n",
    "#Show Method\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Loss Chart is being drawn\n",
    "\n",
    "#Chart Values\n",
    "plt.plot(trainingHistory.history['accuracy'])\n",
    "plt.plot(trainingHistory.history['val_accuracy'])\n",
    "\n",
    "#Chart Tittle\n",
    "plt.title('model accuracy')\n",
    "\n",
    "#Chart Labels\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "#Chart Lines\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "\n",
    "#Show Method\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PersonID</th>\n",
       "      <th>ImageBGR</th>\n",
       "      <th>DetectionType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>270</td>\n",
       "      <td>[[[0, 2, 13], [0, 1, 11], [0, 0, 8], [0, 0, 7]...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "      <td>[[[9, 11, 22], [9, 11, 23], [10, 12, 25], [11,...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>[[[43, 69, 53], [32, 58, 42], [13, 37, 22], [6...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120</td>\n",
       "      <td>[[[161, 124, 104], [160, 124, 105], [159, 125,...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>401</td>\n",
       "      <td>[[[8, 15, 142], [7, 15, 142], [6, 15, 142], [6...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>291</td>\n",
       "      <td>[[[157, 175, 176], [152, 170, 173], [143, 161,...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>302</td>\n",
       "      <td>[[[76, 82, 89], [76, 82, 89], [77, 82, 90], [7...</td>\n",
       "      <td>MultipleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>401</td>\n",
       "      <td>[[[39, 42, 46], [38, 41, 45], [37, 40, 44], [3...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>340</td>\n",
       "      <td>[[[11, 16, 25], [11, 16, 24], [12, 15, 23], [1...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>293</td>\n",
       "      <td>[[[154, 178, 202], [155, 179, 203], [157, 181,...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>915 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PersonID                                           ImageBGR DetectionType\n",
       "0         270  [[[0, 2, 13], [0, 1, 11], [0, 0, 8], [0, 0, 7]...    SingleFace\n",
       "1          80  [[[9, 11, 22], [9, 11, 23], [10, 12, 25], [11,...    SingleFace\n",
       "2          14  [[[43, 69, 53], [32, 58, 42], [13, 37, 22], [6...    SingleFace\n",
       "3         120  [[[161, 124, 104], [160, 124, 105], [159, 125,...    SingleFace\n",
       "4         401  [[[8, 15, 142], [7, 15, 142], [6, 15, 142], [6...    SingleFace\n",
       "..        ...                                                ...           ...\n",
       "910       291  [[[157, 175, 176], [152, 170, 173], [143, 161,...    SingleFace\n",
       "911       302  [[[76, 82, 89], [76, 82, 89], [77, 82, 90], [7...  MultipleFace\n",
       "912       401  [[[39, 42, 46], [38, 41, 45], [37, 40, 44], [3...    SingleFace\n",
       "913       340  [[[11, 16, 25], [11, 16, 24], [12, 15, 23], [1...    SingleFace\n",
       "914       293  [[[154, 178, 202], [155, 179, 203], [157, 181,...    SingleFace\n",
       "\n",
       "[915 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FaceOnly Test data is being read from md5 file\n",
    "testDf = pd.read_pickle(\"../../../Data/ResizedData/FaceOnly/Test.pkl\")\n",
    "testDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(915, 224, 224, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testX is being extracted from testDf as wanted shape\n",
    "testX = np.array(testDf.ImageBGR.values.tolist())\n",
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(915, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testY is being extracted from testDf as wanted shape\n",
    "testY = np.array(testDf.PersonID.values.tolist()).reshape((-1,1))\n",
    "testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 48s 602ms/step - loss: 5.3442 - accuracy: 0.0973\n"
     ]
    }
   ],
   "source": [
    "#Model is being evaluated with test data\n",
    "#Sequence class is being also used for evaluation to convert test data into the same format as training data\n",
    "testResult = model.evaluate(FitSequence(testX, testY, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 5.344244003295898\n"
     ]
    }
   ],
   "source": [
    "#Test Loss is being Printed\n",
    "print('Test Loss: ' + str(testResult[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.0972677618265152\n"
     ]
    }
   ],
   "source": [
    "#Test Accuracy is being Printed\n",
    "print('Test Accuracy: ' + str(testResult[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training1 Inference\n",
    "\n",
    "By looking at the charts, it can be seen that learning does not take place.\n",
    "\n",
    "The model has not learned enough to have any success even on the Training data, even overfitting did not occur.\n",
    "\n",
    "Performance can be improved by trying Hyperparameter Optimization methods.\n",
    "\n",
    "See https://en.wikipedia.org/wiki/Hyperparameter_optimization.\n",
    "\n",
    "Since there is no expectation from this unprocessed dataset, which is already imbalanced.\n",
    "\n",
    "This training will not be focussed on."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py39AI",
   "language": "python",
   "name": "py39ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
