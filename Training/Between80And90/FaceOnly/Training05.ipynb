{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training5\n",
    "\n",
    "In this notebook file, Between80And90-FaceOnly dataset will be read from pkl file.\n",
    "\n",
    "Input(X) and Output(Y) numpy arrays will be created from pandas dataframes.\n",
    "\n",
    "VGG16 pre-trained model will be load and used.\n",
    "\n",
    "The pre-trained model will be set to non-trainable and will only be used for feature extraction.\n",
    "\n",
    "Training will only be performed on the fully connected layers and the output layer, that will be added to the end of the pre-trained model.\n",
    "\n",
    "In this way, the experience gained by the model on very large data sets will be used for this classification problem.\n",
    "\n",
    "This method is known as [**Transfer Learning**](https://en.wikipedia.org/wiki/Transfer_learning \"wikipedia\").\n",
    "\n",
    "A keras utils Sequence class will be defined so that operations can be performed on the data to be used during the training.\n",
    "\n",
    "Performance will be checked with Validation data while training model with Training data.\n",
    "\n",
    "Accuracy and Loss charts will be drawn according to epoch numbers.\n",
    "\n",
    "The results obtained by evaluating the model with Test data will be printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries are being imported\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy Version: 1.22.3\n",
      "pandas Version: 1.4.3\n",
      "tensorflow Version: 2.6.0\n",
      "matplotlib Version: 3.5.2\n"
     ]
    }
   ],
   "source": [
    "#Library versions are being printed\n",
    "print('numpy Version: ' + np.__version__)\n",
    "print('pandas Version: ' + pd.__version__)\n",
    "print('tensorflow Version: ' + tf.__version__)\n",
    "print('matplotlib Version: ' + matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "#GPU will be used for training\n",
    "myGPU = tf.test.gpu_device_name()\n",
    "if myGPU:\n",
    "    print(myGPU)\n",
    "else:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abdullah Gul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amelie Mauresmo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Angelina Jolie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bill Gates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Carlos Menem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Carlos Moya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fidel Castro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>George Robertson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Halle Berry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hamid Karzai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Igor Ivanov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Jean Charest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Jennifer Aniston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Jennifer Lopez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Jiang Zemin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>John Bolton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>John Howard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>John Kerry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>John Snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Joschka Fischer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Jose Maria Aznar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Julianne Moore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Lance Armstrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Lindsay Davenport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Michael Bloomberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Michael Schumacher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Naomi Watts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Nicole Kidman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Paul Bremer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Pervez Musharraf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Pete Sampras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Renee Zellweger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Richard Myers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Saddam Hussein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Spencer Abraham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Tiger Woods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Tim Henman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Tommy Franks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Trent Lott</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Venus Williams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name\n",
       "ID                    \n",
       "0         Abdullah Gul\n",
       "1      Amelie Mauresmo\n",
       "2       Angelina Jolie\n",
       "3           Bill Gates\n",
       "4         Carlos Menem\n",
       "5          Carlos Moya\n",
       "6         Fidel Castro\n",
       "7     George Robertson\n",
       "8          Halle Berry\n",
       "9         Hamid Karzai\n",
       "10         Igor Ivanov\n",
       "11        Jean Charest\n",
       "12    Jennifer Aniston\n",
       "13      Jennifer Lopez\n",
       "14         Jiang Zemin\n",
       "15         John Bolton\n",
       "16         John Howard\n",
       "17          John Kerry\n",
       "18           John Snow\n",
       "19     Joschka Fischer\n",
       "20    Jose Maria Aznar\n",
       "21      Julianne Moore\n",
       "22     Lance Armstrong\n",
       "23   Lindsay Davenport\n",
       "24   Michael Bloomberg\n",
       "25  Michael Schumacher\n",
       "26         Naomi Watts\n",
       "27       Nicole Kidman\n",
       "28         Paul Bremer\n",
       "29    Pervez Musharraf\n",
       "30        Pete Sampras\n",
       "31     Renee Zellweger\n",
       "32       Richard Myers\n",
       "33      Saddam Hussein\n",
       "34     Spencer Abraham\n",
       "35         Tiger Woods\n",
       "36          Tim Henman\n",
       "37        Tommy Franks\n",
       "38          Trent Lott\n",
       "39      Venus Williams"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Person dataframe in Between80And90 is being read from pkl file\n",
    "personDf = pd.read_pickle(\"../../../Data/Between80And90/Person.pkl\")\n",
    "personDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PersonID</th>\n",
       "      <th>ImageBGR</th>\n",
       "      <th>DetectionType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>[[[70, 96, 113], [70, 97, 114], [71, 99, 116],...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>[[[10, 24, 52], [14, 28, 55], [24, 38, 65], [3...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>[[[215, 181, 187], [216, 181, 187], [218, 180,...</td>\n",
       "      <td>MultipleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[[[58, 86, 93], [59, 87, 94], [62, 89, 95], [6...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>[[[167, 189, 201], [167, 190, 202], [168, 192,...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>17</td>\n",
       "      <td>[[[174, 186, 190], [169, 182, 186], [159, 172,...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>30</td>\n",
       "      <td>[[[20, 33, 47], [19, 32, 47], [16, 31, 46], [1...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>13</td>\n",
       "      <td>[[[33, 101, 190], [34, 101, 187], [36, 100, 18...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>23</td>\n",
       "      <td>[[[14, 27, 29], [13, 26, 28], [11, 25, 27], [8...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>17</td>\n",
       "      <td>[[[81, 94, 110], [80, 95, 112], [77, 98, 118],...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>529 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PersonID                                           ImageBGR DetectionType\n",
       "0          28  [[[70, 96, 113], [70, 97, 114], [71, 99, 116],...    SingleFace\n",
       "1          13  [[[10, 24, 52], [14, 28, 55], [24, 38, 65], [3...    SingleFace\n",
       "2          29  [[[215, 181, 187], [216, 181, 187], [218, 180,...  MultipleFace\n",
       "3           1  [[[58, 86, 93], [59, 87, 94], [62, 89, 95], [6...    SingleFace\n",
       "4          16  [[[167, 189, 201], [167, 190, 202], [168, 192,...    SingleFace\n",
       "..        ...                                                ...           ...\n",
       "524        17  [[[174, 186, 190], [169, 182, 186], [159, 172,...    SingleFace\n",
       "525        30  [[[20, 33, 47], [19, 32, 47], [16, 31, 46], [1...    SingleFace\n",
       "526        13  [[[33, 101, 190], [34, 101, 187], [36, 100, 18...    SingleFace\n",
       "527        23  [[[14, 27, 29], [13, 26, 28], [11, 25, 27], [8...    SingleFace\n",
       "528        17  [[[81, 94, 110], [80, 95, 112], [77, 98, 118],...    SingleFace\n",
       "\n",
       "[529 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FaceOnly Training data is being read from pkl file\n",
    "trainingDf = pd.read_pickle(\"../../../Data/Between80And90/FaceOnly/Training.pkl\")\n",
    "trainingDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(529, 224, 224, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trainingX is being extracted from trainingDf as wanted shape\n",
    "#trainingX contains images with pixel values of data type np.uint8 in the range [0, 255]\n",
    "\n",
    "#Many pre-trained models, including the ones to be used within the scope of this project,\n",
    "#have been trained with images containing pixel values in the [-1, 1] range\n",
    "#In this way, the data will be symmetrical and the performance of the Backpropagation algorithm will be increased\n",
    "#See https://en.wikipedia.org/wiki/Backpropagation\n",
    "#See also https://stackoverflow.com/questions/59540276/why-in-preprocessing-image-data-we-need-to-do-zero-centered-data\n",
    "#Therefore, training will be performed by converting pixel values to this range with the simplest method (pixel / 127.5 - 1)\n",
    "\n",
    "trainingX = (np.array(trainingDf.ImageBGR.values.tolist()) / 127.5) - 1\n",
    "trainingX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(529, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trainingY is being extracted from trainingDf as wanted shape\n",
    "trainingY = np.array(trainingDf.PersonID.values.tolist()).reshape((-1,1))\n",
    "trainingY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PersonID</th>\n",
       "      <th>ImageBGR</th>\n",
       "      <th>DetectionType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>[[[227, 227, 227], [227, 227, 227], [227, 227,...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>[[[59, 122, 143], [63, 127, 148], [72, 136, 15...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>[[[90, 112, 124], [89, 111, 123], [88, 110, 12...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>[[[234, 238, 239], [233, 238, 239], [232, 237,...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>[[[77, 100, 96], [83, 107, 101], [96, 120, 112...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>8</td>\n",
       "      <td>[[[39, 10, 0], [34, 8, 0], [26, 4, 0], [21, 2,...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>29</td>\n",
       "      <td>[[[243, 248, 247], [243, 248, 247], [242, 247,...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>5</td>\n",
       "      <td>[[[15, 12, 14], [15, 12, 14], [15, 12, 14], [1...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2</td>\n",
       "      <td>[[[13, 21, 28], [13, 21, 28], [14, 22, 29], [1...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>26</td>\n",
       "      <td>[[[50, 87, 101], [49, 86, 100], [47, 84, 98], ...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PersonID                                           ImageBGR DetectionType\n",
       "0          36  [[[227, 227, 227], [227, 227, 227], [227, 227,...    SingleFace\n",
       "1          27  [[[59, 122, 143], [63, 127, 148], [72, 136, 15...    SingleFace\n",
       "2          22  [[[90, 112, 124], [89, 111, 123], [88, 110, 12...    SingleFace\n",
       "3          33  [[[234, 238, 239], [233, 238, 239], [232, 237,...    SingleFace\n",
       "4          26  [[[77, 100, 96], [83, 107, 101], [96, 120, 112...    SingleFace\n",
       "..        ...                                                ...           ...\n",
       "116         8  [[[39, 10, 0], [34, 8, 0], [26, 4, 0], [21, 2,...    SingleFace\n",
       "117        29  [[[243, 248, 247], [243, 248, 247], [242, 247,...    SingleFace\n",
       "118         5  [[[15, 12, 14], [15, 12, 14], [15, 12, 14], [1...    SingleFace\n",
       "119         2  [[[13, 21, 28], [13, 21, 28], [14, 22, 29], [1...    SingleFace\n",
       "120        26  [[[50, 87, 101], [49, 86, 100], [47, 84, 98], ...    SingleFace\n",
       "\n",
       "[121 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FaceOnly Validation data is being read from pkl file\n",
    "validationDf = pd.read_pickle(\"../../../Data/Between80And90/FaceOnly/Validation.pkl\")\n",
    "validationDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121, 224, 224, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validationX is being extracted from validationDf as wanted shape\n",
    "#validationX contains images with pixel values of data type np.uint8 in the range [0, 255]\n",
    "\n",
    "#Many pre-trained models, including the ones to be used within the scope of this project,\n",
    "#have been trained with images containing pixel values in the [-1, 1] range\n",
    "#In this way, the data will be symmetrical and the performance of the Backpropagation algorithm will be increased\n",
    "#See https://en.wikipedia.org/wiki/Backpropagation\n",
    "#See also https://stackoverflow.com/questions/59540276/why-in-preprocessing-image-data-we-need-to-do-zero-centered-data\n",
    "#Therefore, training will be performed by converting pixel values to this range with the simplest method (pixel / 127.5 - 1)\n",
    "\n",
    "validationX = (np.array(validationDf.ImageBGR.values.tolist()) / 127.5) - 1\n",
    "validationX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validationY is being extracted from validationDf as wanted shape\n",
    "validationY = np.array(validationDf.PersonID.values.tolist()).reshape((-1,1))\n",
    "validationY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#VGG16 pre-trained model is being loaded\n",
    "#The original VGG16 model was trained with images with size of (224, 224, 3) \n",
    "#in BGR color order and pixel values of [-1, 1] (zero centered) as default\n",
    "#See https://keras.io/api/applications/vgg/ for more information\n",
    "#Since images of dataset saved as size of (224, 224, 3) in BGR color order and pixel values of [0, 255]\n",
    "#Pixel values were converted to [-1, 1] range while preparing trainingX and validationX\n",
    "\n",
    "#Model is set to non-trainable\n",
    "#In this way, the convolutional layers that will be used for feature extraction will be used without changing them\n",
    "#Fully connected layers will be fed the feature-map obtained from the pre-trained convolutional model\n",
    "#the training process will be performed on this fully connected layers\n",
    "\n",
    "model = tf.keras.applications.vgg16.VGG16(include_top = False, input_shape = ((224, 224, 3)))\n",
    "model.trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2048)              51382272  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 40)                81960     \n",
      "=================================================================\n",
      "Total params: 70,375,272\n",
      "Trainable params: 55,660,584\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#The pre-trained model is being connected to the fully connected layer where the training will performed\n",
    "#A dropout layer is being added to the the model to prevent overfitting,\n",
    "#and the model is being completed with the addition of the output layer\n",
    "model = tf.keras.models.Sequential([\n",
    "    model,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(2048, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(2048, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(personDf.shape[0], activation = tf.nn.softmax)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model is being compiled with Adam optimizer\n",
    "#Adam optimizer is a common used optimizer\n",
    "#See https://keras.io/api/optimizers/adam/\n",
    "#See also https://towardsdatascience.com/7-tips-to-choose-the-best-optimizer-47bb9c1219e\n",
    "#SparseCategoricalCrossentropy loss function is being used because of the label format of the data\n",
    "#SparseCategoricalAccuracy is being used as metric because of the label format of the data\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name = 'accuracy')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A class inherited from keras utils Sequence is being created\n",
    "class FitSequence(tf.keras.utils.Sequence):\n",
    "    \n",
    "    #Constructor method is being defined\n",
    "    def __init__(self, image, label, batchSize):\n",
    "        self.image, self.label = image, label\n",
    "        self.batchSize = batchSize\n",
    "        \n",
    "        #A numpy array for image indexes is being created\n",
    "        #This array will be used to shuffle the data\n",
    "        self.index = np.arange(self.image.shape[0])\n",
    "    \n",
    "    #__len__ method is being defined\n",
    "    #This method will be used by the model to show the amount of progress of each epoch\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.image.shape[0] / float(self.batchSize)))\n",
    "    \n",
    "    #__getitem__ method is being defined\n",
    "    #The model will retrieve the batches it will use during training by calling this method\n",
    "    #With this method, the data to be used by the model can be manipulated\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        #When the model requests data, the next batch size will be selected based on index array\n",
    "        indexPart = self.index[idx * self.batchSize : (idx + 1) * self.batchSize]\n",
    "        \n",
    "        batchX = self.image[indexPart]\n",
    "        batchY = self.label[indexPart]\n",
    "        return np.array(batchX), np.array(batchY)\n",
    "    \n",
    "    #on_epoch_end method is being defined\n",
    "    #The model will call this method after each epoch is ended\n",
    "    def on_epoch_end(self):\n",
    "        \n",
    "        #At the end of the epoch, the index array is being shuffled \n",
    "        #so that the data in the next epoch is returned in different orders\n",
    "        np.random.shuffle(self.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "34/34 [==============================] - 45s 897ms/step - loss: 6.2637 - accuracy: 0.0529 - val_loss: 3.5945 - val_accuracy: 0.0496\n",
      "Epoch 2/50\n",
      "34/34 [==============================] - 22s 638ms/step - loss: 3.1855 - accuracy: 0.1777 - val_loss: 2.7826 - val_accuracy: 0.2479\n",
      "Epoch 3/50\n",
      "34/34 [==============================] - 22s 639ms/step - loss: 1.6215 - accuracy: 0.5860 - val_loss: 1.9656 - val_accuracy: 0.4628\n",
      "Epoch 4/50\n",
      "34/34 [==============================] - 22s 639ms/step - loss: 0.4635 - accuracy: 0.8715 - val_loss: 1.8875 - val_accuracy: 0.5041\n",
      "Epoch 5/50\n",
      "34/34 [==============================] - 22s 638ms/step - loss: 0.1456 - accuracy: 0.9679 - val_loss: 1.5657 - val_accuracy: 0.5785\n",
      "Epoch 6/50\n",
      "34/34 [==============================] - 22s 638ms/step - loss: 0.0349 - accuracy: 0.9981 - val_loss: 1.3198 - val_accuracy: 0.6529\n",
      "Epoch 7/50\n",
      "34/34 [==============================] - 22s 638ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.1969 - val_accuracy: 0.6777\n",
      "Epoch 8/50\n",
      "34/34 [==============================] - 22s 641ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.1455 - val_accuracy: 0.6860\n",
      "Epoch 9/50\n",
      "34/34 [==============================] - 22s 645ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.1858 - val_accuracy: 0.7107\n",
      "Epoch 10/50\n",
      "34/34 [==============================] - 22s 640ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.1559 - val_accuracy: 0.7025\n",
      "Epoch 11/50\n",
      "34/34 [==============================] - 22s 644ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.1420 - val_accuracy: 0.7025\n",
      "Epoch 12/50\n",
      "34/34 [==============================] - 22s 647ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.1475 - val_accuracy: 0.7025\n",
      "Epoch 13/50\n",
      "34/34 [==============================] - 22s 649ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.1402 - val_accuracy: 0.7025\n",
      "Epoch 14/50\n",
      "34/34 [==============================] - 22s 651ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.1458 - val_accuracy: 0.6942\n",
      "Epoch 15/50\n",
      "34/34 [==============================] - 22s 652ms/step - loss: 7.6434e-04 - accuracy: 1.0000 - val_loss: 1.1442 - val_accuracy: 0.7190\n",
      "Epoch 16/50\n",
      "34/34 [==============================] - 22s 654ms/step - loss: 7.7726e-04 - accuracy: 1.0000 - val_loss: 1.1700 - val_accuracy: 0.7025\n",
      "Epoch 17/50\n",
      "34/34 [==============================] - 22s 654ms/step - loss: 6.4076e-04 - accuracy: 1.0000 - val_loss: 1.1601 - val_accuracy: 0.7107\n",
      "Epoch 18/50\n",
      "34/34 [==============================] - 22s 650ms/step - loss: 6.2537e-04 - accuracy: 1.0000 - val_loss: 1.1458 - val_accuracy: 0.7107\n",
      "Epoch 19/50\n",
      "34/34 [==============================] - 22s 648ms/step - loss: 4.7470e-04 - accuracy: 1.0000 - val_loss: 1.1358 - val_accuracy: 0.7107\n",
      "Epoch 20/50\n",
      "34/34 [==============================] - 22s 650ms/step - loss: 4.3364e-04 - accuracy: 1.0000 - val_loss: 1.1357 - val_accuracy: 0.7107\n",
      "Epoch 21/50\n",
      "34/34 [==============================] - 22s 652ms/step - loss: 4.2440e-04 - accuracy: 1.0000 - val_loss: 1.1442 - val_accuracy: 0.7025\n",
      "Epoch 22/50\n",
      "34/34 [==============================] - 22s 657ms/step - loss: 4.1407e-04 - accuracy: 1.0000 - val_loss: 1.1541 - val_accuracy: 0.7025\n",
      "Epoch 23/50\n",
      "34/34 [==============================] - 22s 660ms/step - loss: 3.7387e-04 - accuracy: 1.0000 - val_loss: 1.1647 - val_accuracy: 0.7025\n",
      "Epoch 24/50\n",
      "34/34 [==============================] - 22s 660ms/step - loss: 3.2803e-04 - accuracy: 1.0000 - val_loss: 1.1546 - val_accuracy: 0.7025\n",
      "Epoch 25/50\n",
      "34/34 [==============================] - 23s 668ms/step - loss: 3.8915e-04 - accuracy: 1.0000 - val_loss: 1.1554 - val_accuracy: 0.7107\n",
      "Epoch 26/50\n",
      "34/34 [==============================] - 22s 660ms/step - loss: 3.4873e-04 - accuracy: 1.0000 - val_loss: 1.1743 - val_accuracy: 0.7107\n",
      "Epoch 27/50\n",
      "34/34 [==============================] - 22s 659ms/step - loss: 3.4846e-04 - accuracy: 1.0000 - val_loss: 1.1592 - val_accuracy: 0.7190\n",
      "Epoch 28/50\n",
      "34/34 [==============================] - 22s 661ms/step - loss: 3.4075e-04 - accuracy: 1.0000 - val_loss: 1.1510 - val_accuracy: 0.7273\n",
      "Epoch 29/50\n",
      "34/34 [==============================] - 23s 669ms/step - loss: 2.5528e-04 - accuracy: 1.0000 - val_loss: 1.1493 - val_accuracy: 0.7190\n",
      "Epoch 30/50\n",
      "34/34 [==============================] - 23s 667ms/step - loss: 2.1864e-04 - accuracy: 1.0000 - val_loss: 1.1468 - val_accuracy: 0.7190\n",
      "Epoch 31/50\n",
      "34/34 [==============================] - 23s 669ms/step - loss: 2.2130e-04 - accuracy: 1.0000 - val_loss: 1.1442 - val_accuracy: 0.7190\n",
      "Epoch 32/50\n",
      "34/34 [==============================] - 23s 674ms/step - loss: 2.2874e-04 - accuracy: 1.0000 - val_loss: 1.1449 - val_accuracy: 0.7107\n",
      "Epoch 33/50\n",
      "34/34 [==============================] - 23s 678ms/step - loss: 2.1958e-04 - accuracy: 1.0000 - val_loss: 1.1589 - val_accuracy: 0.7107\n",
      "Epoch 34/50\n",
      "34/34 [==============================] - 23s 676ms/step - loss: 1.7417e-04 - accuracy: 1.0000 - val_loss: 1.1655 - val_accuracy: 0.7107\n",
      "Epoch 35/50\n",
      "34/34 [==============================] - 23s 677ms/step - loss: 1.6930e-04 - accuracy: 1.0000 - val_loss: 1.1741 - val_accuracy: 0.7025\n",
      "Epoch 36/50\n",
      "34/34 [==============================] - 23s 677ms/step - loss: 1.6397e-04 - accuracy: 1.0000 - val_loss: 1.1769 - val_accuracy: 0.7107\n",
      "Epoch 37/50\n",
      "34/34 [==============================] - 23s 677ms/step - loss: 1.6944e-04 - accuracy: 1.0000 - val_loss: 1.1784 - val_accuracy: 0.7107\n",
      "Epoch 38/50\n",
      "34/34 [==============================] - 23s 672ms/step - loss: 2.2052e-04 - accuracy: 1.0000 - val_loss: 1.1781 - val_accuracy: 0.6942\n",
      "Epoch 39/50\n",
      "34/34 [==============================] - 23s 674ms/step - loss: 1.4820e-04 - accuracy: 1.0000 - val_loss: 1.1685 - val_accuracy: 0.6860\n",
      "Epoch 40/50\n",
      "34/34 [==============================] - 23s 690ms/step - loss: 1.4958e-04 - accuracy: 1.0000 - val_loss: 1.1692 - val_accuracy: 0.6942\n",
      "Epoch 41/50\n",
      "34/34 [==============================] - 23s 677ms/step - loss: 1.2477e-04 - accuracy: 1.0000 - val_loss: 1.1654 - val_accuracy: 0.7025\n",
      "Epoch 42/50\n",
      "34/34 [==============================] - 23s 678ms/step - loss: 1.2049e-04 - accuracy: 1.0000 - val_loss: 1.1693 - val_accuracy: 0.7107\n",
      "Epoch 43/50\n",
      "34/34 [==============================] - 23s 674ms/step - loss: 1.2844e-04 - accuracy: 1.0000 - val_loss: 1.1776 - val_accuracy: 0.7190\n",
      "Epoch 44/50\n",
      "34/34 [==============================] - 22s 663ms/step - loss: 1.6973e-04 - accuracy: 1.0000 - val_loss: 1.1819 - val_accuracy: 0.7025\n",
      "Epoch 45/50\n",
      "34/34 [==============================] - 23s 668ms/step - loss: 1.3731e-04 - accuracy: 1.0000 - val_loss: 1.1767 - val_accuracy: 0.7025\n",
      "Epoch 46/50\n",
      "34/34 [==============================] - 23s 668ms/step - loss: 1.2043e-04 - accuracy: 1.0000 - val_loss: 1.1787 - val_accuracy: 0.6942\n",
      "Epoch 47/50\n",
      "34/34 [==============================] - 23s 668ms/step - loss: 1.0482e-04 - accuracy: 1.0000 - val_loss: 1.1751 - val_accuracy: 0.6942\n",
      "Epoch 48/50\n",
      "34/34 [==============================] - 23s 677ms/step - loss: 9.2364e-05 - accuracy: 1.0000 - val_loss: 1.1649 - val_accuracy: 0.7107\n",
      "Epoch 49/50\n",
      "34/34 [==============================] - 23s 669ms/step - loss: 8.7752e-05 - accuracy: 1.0000 - val_loss: 1.1658 - val_accuracy: 0.7107\n",
      "Epoch 50/50\n",
      "34/34 [==============================] - 22s 661ms/step - loss: 9.1342e-05 - accuracy: 1.0000 - val_loss: 1.1698 - val_accuracy: 0.7107\n"
     ]
    }
   ],
   "source": [
    "#model is being trained with 50 epochs and 16 batchSize using GPU\n",
    "#A small batchSize value is being chosen to prevent GPU memory problem\n",
    "#Large batchSize reduce training time while also generally providing better results\n",
    "with tf.device(myGPU):\n",
    "    trainingHistory = model.fit(\n",
    "        FitSequence(trainingX, trainingY, 16),\n",
    "        epochs = 50,\n",
    "        validation_data = FitSequence(validationX, validationY, 16)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Loss Chart is being drawn\n",
    "\n",
    "#Chart Values\n",
    "plt.plot(trainingHistory.history['loss'])\n",
    "plt.plot(trainingHistory.history['val_loss'])\n",
    "\n",
    "#Chart Tittle\n",
    "plt.title('Model Loss Chart')\n",
    "\n",
    "#Chart Labels\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "#Chart Lines\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "\n",
    "#Show Method\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Loss Chart is being drawn\n",
    "\n",
    "#Chart Values\n",
    "plt.plot(trainingHistory.history['accuracy'])\n",
    "plt.plot(trainingHistory.history['val_accuracy'])\n",
    "\n",
    "#Chart Tittle\n",
    "plt.title('model accuracy')\n",
    "\n",
    "#Chart Labels\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "#Chart Lines\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "\n",
    "#Show Method\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PersonID</th>\n",
       "      <th>ImageBGR</th>\n",
       "      <th>DetectionType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[[[43, 69, 53], [32, 58, 42], [13, 37, 22], [6...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>[[[25, 29, 24], [24, 29, 24], [23, 29, 24], [2...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[[[176, 186, 216], [176, 186, 216], [176, 187,...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>[[[136, 157, 155], [136, 157, 155], [137, 157,...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>[[[46, 48, 49], [43, 45, 46], [37, 39, 40], [3...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>34</td>\n",
       "      <td>[[[81, 86, 95], [82, 88, 97], [84, 93, 103], [...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>31</td>\n",
       "      <td>[[[88, 90, 98], [88, 90, 98], [88, 90, 98], [8...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>11</td>\n",
       "      <td>[[[20, 36, 42], [28, 44, 51], [43, 59, 65], [5...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>14</td>\n",
       "      <td>[[[12, 31, 38], [12, 31, 38], [11, 31, 37], [1...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>27</td>\n",
       "      <td>[[[154, 178, 202], [155, 179, 203], [157, 181,...</td>\n",
       "      <td>SingleFace</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PersonID                                           ImageBGR DetectionType\n",
       "0           1  [[[43, 69, 53], [32, 58, 42], [13, 37, 22], [6...    SingleFace\n",
       "1          13  [[[25, 29, 24], [24, 29, 24], [23, 29, 24], [2...    SingleFace\n",
       "2           1  [[[176, 186, 216], [176, 186, 216], [176, 187,...    SingleFace\n",
       "3           9  [[[136, 157, 155], [136, 157, 155], [137, 157,...    SingleFace\n",
       "4          20  [[[46, 48, 49], [43, 45, 46], [37, 39, 40], [3...    SingleFace\n",
       "..        ...                                                ...           ...\n",
       "115        34  [[[81, 86, 95], [82, 88, 97], [84, 93, 103], [...    SingleFace\n",
       "116        31  [[[88, 90, 98], [88, 90, 98], [88, 90, 98], [8...    SingleFace\n",
       "117        11  [[[20, 36, 42], [28, 44, 51], [43, 59, 65], [5...    SingleFace\n",
       "118        14  [[[12, 31, 38], [12, 31, 38], [11, 31, 37], [1...    SingleFace\n",
       "119        27  [[[154, 178, 202], [155, 179, 203], [157, 181,...    SingleFace\n",
       "\n",
       "[120 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FaceOnly Test data is being read from pkl file\n",
    "testDf = pd.read_pickle(\"../../../Data/Between80And90/FaceOnly/Test.pkl\")\n",
    "testDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 224, 224, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testX is being extracted from testDf as wanted shape\n",
    "#Pixel values are being converted  to the [-1, 1] range with the simplest method (pixel / 127.5 - 1)\n",
    "testX = (np.array(testDf.ImageBGR.values.tolist()) / 127.5) - 1\n",
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testY is being extracted from testDf as wanted shape\n",
    "testY = np.array(testDf.PersonID.values.tolist()).reshape((-1,1))\n",
    "testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 10s 1s/step - loss: 1.5467 - accuracy: 0.6500\n"
     ]
    }
   ],
   "source": [
    "#Model is being evaluated with test data\n",
    "#Sequence class is being also used for evaluation to convert test data into the same format as training data\n",
    "testResult = model.evaluate(FitSequence(testX, testY, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.546744704246521\n"
     ]
    }
   ],
   "source": [
    "#Test Loss is being Printed\n",
    "print('Test Loss: ' + str(testResult[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6499999761581421\n"
     ]
    }
   ],
   "source": [
    "#Test Accuracy is being Printed\n",
    "print('Test Accuracy: ' + str(testResult[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training5 Inference\n",
    "\n",
    "When looking at the charts, it can be seen that the Training accuracy is close to 100% and the Validation accuracy is close to 72%.\n",
    "\n",
    "A similar architecture was trained with same data in the Training1 notebook file without the Transfer Learning method.\n",
    "\n",
    "The results are much better than those in the Training1 notebook file.\n",
    "\n",
    "This example clearly demonstrates the power of Transfer Learning.\n",
    "\n",
    "Performance can be improved by trying Hyperparameter Optimization methods.\n",
    "\n",
    "See https://en.wikipedia.org/wiki/Hyperparameter_optimization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py39AI",
   "language": "python",
   "name": "py39ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
