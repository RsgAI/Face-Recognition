{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training5\n",
    "\n",
    "In this notebook file, FirstQuarter-FullPhoto dataset will be read from pkl file.\n",
    "\n",
    "Input(X) and Output(Y) numpy arrays will be created from pandas dataframes.\n",
    "\n",
    "VGG16 pre-trained model will be load and used.\n",
    "\n",
    "The pre-trained model will be set to non-trainable and will only be used for feature extraction.\n",
    "\n",
    "Training will only be performed on the fully connected layers and the output layer, that will be added to the end of the pre-trained model.\n",
    "\n",
    "In this way, the experience gained by the model on very large data sets will be used for this classification problem.\n",
    "\n",
    "This method is known as [**Transfer Learning**](https://en.wikipedia.org/wiki/Transfer_learning \"wikipedia\").\n",
    "\n",
    "A keras utils Sequence class will be defined so that operations can be performed on the data to be used during the training.\n",
    "\n",
    "Performance will be checked with Validation data while training model with Training data.\n",
    "\n",
    "Accuracy and Loss charts will be drawn according to epoch numbers.\n",
    "\n",
    "The results obtained by evaluating the model with Test data will be printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries are being imported\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy Version: 1.22.3\n",
      "pandas Version: 1.4.3\n",
      "tensorflow Version: 2.6.0\n",
      "matplotlib Version: 3.5.2\n"
     ]
    }
   ],
   "source": [
    "#Library versions are being printed\n",
    "print('numpy Version: ' + np.__version__)\n",
    "print('pandas Version: ' + pd.__version__)\n",
    "print('tensorflow Version: ' + tf.__version__)\n",
    "print('matplotlib Version: ' + matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "#GPU will be used for training\n",
    "myGPU = tf.test.gpu_device_name()\n",
    "if myGPU:\n",
    "    print(myGPU)\n",
    "else:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ahmed Chalabi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ai Sugiyama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alan Greenspan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alastair Campbell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Allyson Felix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Wayne Ferreira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>William Macy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Woody Allen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Xanana Gusmao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Xavier Malisse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name\n",
       "ID                    \n",
       "0        Ahmed Chalabi\n",
       "1          Ai Sugiyama\n",
       "2       Alan Greenspan\n",
       "3    Alastair Campbell\n",
       "4        Allyson Felix\n",
       "..                 ...\n",
       "107     Wayne Ferreira\n",
       "108       William Macy\n",
       "109        Woody Allen\n",
       "110      Xanana Gusmao\n",
       "111     Xavier Malisse\n",
       "\n",
       "[112 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Person dataframe in FirstQuarter is being read from pkl file\n",
    "personDf = pd.read_pickle(\"../../../Data/FirstQuarter/Person.pkl\")\n",
    "personDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PersonID</th>\n",
       "      <th>ImageBGR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "      <td>[[[59, 59, 53], [58, 58, 52], [57, 56, 51], [5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>[[[158, 177, 174], [158, 177, 174], [158, 177,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101</td>\n",
       "      <td>[[[43, 17, 77], [45, 21, 78], [43, 20, 72], [4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>55</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>79</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>54</td>\n",
       "      <td>[[[7, 0, 0], [7, 0, 0], [7, 0, 0], [7, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>29</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [1, 0, 0], [2, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>2</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>448 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PersonID                                           ImageBGR\n",
       "0          95  [[[59, 59, 53], [58, 58, 52], [57, 56, 51], [5...\n",
       "1          63  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "2          94  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "3          10  [[[158, 177, 174], [158, 177, 174], [158, 177,...\n",
       "4         101  [[[43, 17, 77], [45, 21, 78], [43, 20, 72], [4...\n",
       "..        ...                                                ...\n",
       "443        55  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "444        79  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "445        54  [[[7, 0, 0], [7, 0, 0], [7, 0, 0], [7, 0, 0], ...\n",
       "446        29  [[[0, 0, 0], [0, 0, 0], [1, 0, 0], [2, 0, 0], ...\n",
       "447         2  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "\n",
       "[448 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FullPhoto Training data is being read from pkl file\n",
    "trainingDf = pd.read_pickle(\"../../../Data/FirstQuarter/FullPhoto/Training.pkl\")\n",
    "trainingDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(448, 224, 224, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trainingX is being extracted from trainingDf as wanted shape\n",
    "#trainingX contains images with pixel values of data type np.uint8 in the range [0, 255]\n",
    "\n",
    "#Many pre-trained models, including the ones to be used within the scope of this project,\n",
    "#have been trained with images containing pixel values in the [-1, 1] range\n",
    "#In this way, the data will be symmetrical and the performance of the Backpropagation algorithm will be increased\n",
    "#See https://en.wikipedia.org/wiki/Backpropagation\n",
    "#See also https://stackoverflow.com/questions/59540276/why-in-preprocessing-image-data-we-need-to-do-zero-centered-data\n",
    "#Therefore, training will be performed by converting pixel values to this range with the simplest method (pixel / 127.5 - 1)\n",
    "\n",
    "trainingX = (np.array(trainingDf.ImageBGR.values.tolist()) / 127.5) - 1\n",
    "trainingX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(448, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trainingY is being extracted from trainingDf as wanted shape\n",
    "trainingY = np.array(trainingDf.PersonID.values.tolist()).reshape((-1,1))\n",
    "trainingY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PersonID</th>\n",
       "      <th>ImageBGR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>[[[60, 67, 60], [60, 67, 60], [60, 67, 60], [5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>[[[0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>[[[0, 1, 2], [0, 0, 0], [1, 1, 0], [2, 1, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>[[[58, 109, 149], [58, 109, 149], [58, 109, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>75</td>\n",
       "      <td>[[[0, 0, 3], [0, 0, 2], [0, 0, 1], [0, 0, 1], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>81</td>\n",
       "      <td>[[[0, 1, 3], [0, 0, 3], [1, 0, 4], [4, 0, 5], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>56</td>\n",
       "      <td>[[[251, 255, 255], [251, 255, 255], [251, 255,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>111</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>68</td>\n",
       "      <td>[[[10, 16, 15], [9, 15, 14], [8, 12, 12], [9, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>53</td>\n",
       "      <td>[[[181, 213, 219], [183, 215, 221], [184, 216,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>74</td>\n",
       "      <td>[[[139, 166, 170], [140, 167, 171], [140, 166,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>44</td>\n",
       "      <td>[[[2, 0, 0], [2, 0, 0], [2, 0, 0], [2, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>35</td>\n",
       "      <td>[[[66, 81, 90], [66, 81, 90], [66, 81, 90], [6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>102</td>\n",
       "      <td>[[[99, 82, 69], [102, 85, 72], [106, 89, 76], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>64</td>\n",
       "      <td>[[[58, 48, 65], [58, 48, 65], [57, 46, 64], [5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>59</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>23</td>\n",
       "      <td>[[[22, 60, 65], [21, 59, 64], [20, 57, 63], [2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>101</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>96</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>36</td>\n",
       "      <td>[[[108, 95, 51], [106, 93, 50], [105, 92, 48],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>61</td>\n",
       "      <td>[[[21, 28, 45], [18, 25, 40], [20, 28, 40], [2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>16</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>94</td>\n",
       "      <td>[[[63, 51, 41], [68, 56, 46], [73, 61, 51], [7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>54</td>\n",
       "      <td>[[[125, 193, 192], [125, 193, 192], [125, 193,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>32</td>\n",
       "      <td>[[[142, 185, 224], [151, 194, 233], [149, 192,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>25</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>30</td>\n",
       "      <td>[[[2, 3, 0], [2, 3, 0], [2, 3, 0], [2, 3, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>107</td>\n",
       "      <td>[[[15, 10, 5], [15, 10, 6], [15, 10, 6], [16, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>89</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>6</td>\n",
       "      <td>[[[2, 0, 0], [2, 0, 0], [2, 0, 0], [2, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5</td>\n",
       "      <td>[[[0, 1, 0], [0, 1, 0], [1, 1, 0], [3, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>20</td>\n",
       "      <td>[[[122, 148, 208], [119, 147, 207], [118, 145,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>98</td>\n",
       "      <td>[[[46, 52, 57], [44, 50, 55], [42, 48, 53], [4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>33</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>77</td>\n",
       "      <td>[[[239, 238, 242], [239, 238, 242], [238, 237,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>63</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 1, 0], [1, 1, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>11</td>\n",
       "      <td>[[[2, 0, 0], [2, 0, 0], [2, 0, 0], [2, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>29</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>99</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>[[[0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>93</td>\n",
       "      <td>[[[34, 59, 75], [34, 59, 75], [35, 60, 76], [3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>8</td>\n",
       "      <td>[[[215, 197, 238], [215, 197, 238], [215, 197,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>103</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>69</td>\n",
       "      <td>[[[243, 254, 255], [238, 249, 251], [234, 243,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>7</td>\n",
       "      <td>[[[86, 103, 152], [91, 107, 159], [93, 107, 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>62</td>\n",
       "      <td>[[[34, 53, 56], [29, 48, 51], [24, 41, 44], [1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>19</td>\n",
       "      <td>[[[181, 210, 241], [180, 210, 239], [180, 210,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>71</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>66</td>\n",
       "      <td>[[[2, 4, 7], [2, 3, 6], [2, 3, 6], [2, 3, 6], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>109</td>\n",
       "      <td>[[[2, 7, 1], [2, 9, 2], [2, 6, 2], [2, 6, 2], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>12</td>\n",
       "      <td>[[[2, 0, 0], [2, 0, 0], [2, 0, 0], [2, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>24</td>\n",
       "      <td>[[[45, 87, 62], [45, 87, 62], [44, 86, 61], [4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PersonID                                           ImageBGR\n",
       "0         50  [[[60, 67, 60], [60, 67, 60], [60, 67, 60], [5...\n",
       "1         73  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "2         40  [[[0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], ...\n",
       "3         27  [[[0, 1, 2], [0, 0, 0], [1, 1, 0], [2, 1, 0], ...\n",
       "4         18  [[[58, 109, 149], [58, 109, 149], [58, 109, 14...\n",
       "5         75  [[[0, 0, 3], [0, 0, 2], [0, 0, 1], [0, 0, 1], ...\n",
       "6         81  [[[0, 1, 3], [0, 0, 3], [1, 0, 4], [4, 0, 5], ...\n",
       "7         56  [[[251, 255, 255], [251, 255, 255], [251, 255,...\n",
       "8        111  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "9         68  [[[10, 16, 15], [9, 15, 14], [8, 12, 12], [9, ...\n",
       "10        10  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "11        53  [[[181, 213, 219], [183, 215, 221], [184, 216,...\n",
       "12        74  [[[139, 166, 170], [140, 167, 171], [140, 166,...\n",
       "13        44  [[[2, 0, 0], [2, 0, 0], [2, 0, 0], [2, 0, 0], ...\n",
       "14        35  [[[66, 81, 90], [66, 81, 90], [66, 81, 90], [6...\n",
       "15       102  [[[99, 82, 69], [102, 85, 72], [106, 89, 76], ...\n",
       "16        64  [[[58, 48, 65], [58, 48, 65], [57, 46, 64], [5...\n",
       "17        59  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "18        23  [[[22, 60, 65], [21, 59, 64], [20, 57, 63], [2...\n",
       "19       101  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "20        96  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "21        36  [[[108, 95, 51], [106, 93, 50], [105, 92, 48],...\n",
       "22        61  [[[21, 28, 45], [18, 25, 40], [20, 28, 40], [2...\n",
       "23        16  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "24        94  [[[63, 51, 41], [68, 56, 46], [73, 61, 51], [7...\n",
       "25        54  [[[125, 193, 192], [125, 193, 192], [125, 193,...\n",
       "26        32  [[[142, 185, 224], [151, 194, 233], [149, 192,...\n",
       "27        25  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "28        30  [[[2, 3, 0], [2, 3, 0], [2, 3, 0], [2, 3, 0], ...\n",
       "29       107  [[[15, 10, 5], [15, 10, 6], [15, 10, 6], [16, ...\n",
       "30        89  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "31         6  [[[2, 0, 0], [2, 0, 0], [2, 0, 0], [2, 0, 0], ...\n",
       "32         5  [[[0, 1, 0], [0, 1, 0], [1, 1, 0], [3, 0, 0], ...\n",
       "33        20  [[[122, 148, 208], [119, 147, 207], [118, 145,...\n",
       "34        98  [[[46, 52, 57], [44, 50, 55], [42, 48, 53], [4...\n",
       "35        33  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "36        77  [[[239, 238, 242], [239, 238, 242], [238, 237,...\n",
       "37        63  [[[0, 0, 0], [0, 0, 0], [0, 1, 0], [1, 1, 0], ...\n",
       "38        11  [[[2, 0, 0], [2, 0, 0], [2, 0, 0], [2, 0, 0], ...\n",
       "39        29  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "40        99  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "41         0  [[[0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], ...\n",
       "42        93  [[[34, 59, 75], [34, 59, 75], [35, 60, 76], [3...\n",
       "43         8  [[[215, 197, 238], [215, 197, 238], [215, 197,...\n",
       "44       103  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "45        45  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "46        69  [[[243, 254, 255], [238, 249, 251], [234, 243,...\n",
       "47         7  [[[86, 103, 152], [91, 107, 159], [93, 107, 16...\n",
       "48        62  [[[34, 53, 56], [29, 48, 51], [24, 41, 44], [1...\n",
       "49        19  [[[181, 210, 241], [180, 210, 239], [180, 210,...\n",
       "50        71  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "51        66  [[[2, 4, 7], [2, 3, 6], [2, 3, 6], [2, 3, 6], ...\n",
       "52       109  [[[2, 7, 1], [2, 9, 2], [2, 6, 2], [2, 6, 2], ...\n",
       "53        12  [[[2, 0, 0], [2, 0, 0], [2, 0, 0], [2, 0, 0], ...\n",
       "54        24  [[[45, 87, 62], [45, 87, 62], [44, 86, 61], [4..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FullPhoto Validation data is being read from pkl file\n",
    "validationDf = pd.read_pickle(\"../../../Data/FirstQuarter/FullPhoto/Validation.pkl\")\n",
    "validationDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 224, 224, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validationX is being extracted from validationDf as wanted shape\n",
    "#validationX contains images with pixel values of data type np.uint8 in the range [0, 255]\n",
    "\n",
    "#Many pre-trained models, including the ones to be used within the scope of this project,\n",
    "#have been trained with images containing pixel values in the [-1, 1] range\n",
    "#In this way, the data will be symmetrical and the performance of the Backpropagation algorithm will be increased\n",
    "#See https://en.wikipedia.org/wiki/Backpropagation\n",
    "#See also https://stackoverflow.com/questions/59540276/why-in-preprocessing-image-data-we-need-to-do-zero-centered-data\n",
    "#Therefore, training will be performed by converting pixel values to this range with the simplest method (pixel / 127.5 - 1)\n",
    "\n",
    "validationX = (np.array(validationDf.ImageBGR.values.tolist()) / 127.5) - 1\n",
    "validationX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validationY is being extracted from validationDf as wanted shape\n",
    "validationY = np.array(validationDf.PersonID.values.tolist()).reshape((-1,1))\n",
    "validationY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#VGG16 pre-trained model is being loaded\n",
    "#The original VGG16 model was trained with images with size of (224, 224, 3) \n",
    "#in BGR color order and pixel values of [-1, 1] (zero centered) as default\n",
    "#See https://keras.io/api/applications/vgg/ for more information\n",
    "#Since images of dataset saved as size of (224, 224, 3) in BGR color order and pixel values of [0, 255]\n",
    "#Pixel values were converted to [-1, 1] range while preparing trainingX and validationX\n",
    "\n",
    "#Model is set to non-trainable\n",
    "#In this way, the convolutional layers that will be used for feature extraction will be used without changing them\n",
    "#Fully connected layers will be fed the feature-map obtained from the pre-trained convolutional model\n",
    "#the training process will be performed on this fully connected layers\n",
    "\n",
    "model = tf.keras.applications.vgg16.VGG16(include_top = False, input_shape = ((224, 224, 3)))\n",
    "model.trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2048)              51382272  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 112)               229488    \n",
      "=================================================================\n",
      "Total params: 70,522,800\n",
      "Trainable params: 55,808,112\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#The pre-trained model is being connected to the fully connected layer where the training will performed\n",
    "#A dropout layer is being added to the the model to prevent overfitting,\n",
    "#and the model is being completed with the addition of the output layer\n",
    "model = tf.keras.models.Sequential([\n",
    "    model,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(2048, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(2048, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(personDf.shape[0], activation = tf.nn.softmax)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model is being compiled with Adam optimizer\n",
    "#Adam optimizer is a common used optimizer\n",
    "#See https://keras.io/api/optimizers/adam/\n",
    "#See also https://towardsdatascience.com/7-tips-to-choose-the-best-optimizer-47bb9c1219e\n",
    "#SparseCategoricalCrossentropy loss function is being used because of the label format of the data\n",
    "#SparseCategoricalAccuracy is being used as metric because of the label format of the data\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name = 'accuracy')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A class inherited from keras utils Sequence is being created\n",
    "class FitSequence(tf.keras.utils.Sequence):\n",
    "    \n",
    "    #Constructor method is being defined\n",
    "    def __init__(self, image, label, batchSize):\n",
    "        self.image, self.label = image, label\n",
    "        self.batchSize = batchSize\n",
    "        \n",
    "        #A numpy array for image indexes is being created\n",
    "        #This array will be used to shuffle the data\n",
    "        self.index = np.arange(self.image.shape[0])\n",
    "    \n",
    "    #__len__ method is being defined\n",
    "    #This method will be used by the model to show the amount of progress of each epoch\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.image.shape[0] / float(self.batchSize)))\n",
    "    \n",
    "    #__getitem__ method is being defined\n",
    "    #The model will retrieve the batches it will use during training by calling this method\n",
    "    #With this method, the data to be used by the model can be manipulated\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        #When the model requests data, the next batch size will be selected based on index array\n",
    "        indexPart = self.index[idx * self.batchSize : (idx + 1) * self.batchSize]\n",
    "        \n",
    "        batchX = self.image[indexPart]\n",
    "        batchY = self.label[indexPart]\n",
    "        return np.array(batchX), np.array(batchY)\n",
    "    \n",
    "    #on_epoch_end method is being defined\n",
    "    #The model will call this method after each epoch is ended\n",
    "    def on_epoch_end(self):\n",
    "        \n",
    "        #At the end of the epoch, the index array is being shuffled \n",
    "        #so that the data in the next epoch is returned in different orders\n",
    "        np.random.shuffle(self.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "28/28 [==============================] - 41s 832ms/step - loss: 6.1236 - accuracy: 0.0045 - val_loss: 4.6743 - val_accuracy: 0.0182\n",
      "Epoch 2/50\n",
      "28/28 [==============================] - 17s 604ms/step - loss: 4.6151 - accuracy: 0.0558 - val_loss: 4.5033 - val_accuracy: 0.0182\n",
      "Epoch 3/50\n",
      "28/28 [==============================] - 17s 604ms/step - loss: 3.4789 - accuracy: 0.2188 - val_loss: 4.2224 - val_accuracy: 0.0909\n",
      "Epoch 4/50\n",
      "28/28 [==============================] - 17s 604ms/step - loss: 1.7115 - accuracy: 0.6205 - val_loss: 4.2949 - val_accuracy: 0.0909\n",
      "Epoch 5/50\n",
      "28/28 [==============================] - 17s 604ms/step - loss: 0.5477 - accuracy: 0.8750 - val_loss: 4.1209 - val_accuracy: 0.1818\n",
      "Epoch 6/50\n",
      "28/28 [==============================] - 17s 609ms/step - loss: 0.0784 - accuracy: 0.9911 - val_loss: 4.5687 - val_accuracy: 0.1818\n",
      "Epoch 7/50\n",
      "28/28 [==============================] - 17s 613ms/step - loss: 0.0336 - accuracy: 0.9911 - val_loss: 4.6333 - val_accuracy: 0.1636\n",
      "Epoch 8/50\n",
      "28/28 [==============================] - 17s 621ms/step - loss: 0.0397 - accuracy: 0.9933 - val_loss: 4.2235 - val_accuracy: 0.2182\n",
      "Epoch 9/50\n",
      "28/28 [==============================] - 17s 621ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 4.1059 - val_accuracy: 0.1455\n",
      "Epoch 10/50\n",
      "28/28 [==============================] - 17s 625ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 4.0744 - val_accuracy: 0.2182\n",
      "Epoch 11/50\n",
      "28/28 [==============================] - 17s 619ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.0602 - val_accuracy: 0.2000\n",
      "Epoch 12/50\n",
      "28/28 [==============================] - 17s 615ms/step - loss: 8.6296e-04 - accuracy: 1.0000 - val_loss: 4.0799 - val_accuracy: 0.1818\n",
      "Epoch 13/50\n",
      "28/28 [==============================] - 17s 607ms/step - loss: 7.1449e-04 - accuracy: 1.0000 - val_loss: 4.0850 - val_accuracy: 0.1818\n",
      "Epoch 14/50\n",
      "28/28 [==============================] - 17s 613ms/step - loss: 6.2567e-04 - accuracy: 1.0000 - val_loss: 4.1033 - val_accuracy: 0.1818\n",
      "Epoch 15/50\n",
      "28/28 [==============================] - 17s 624ms/step - loss: 5.4382e-04 - accuracy: 1.0000 - val_loss: 4.1106 - val_accuracy: 0.1818\n",
      "Epoch 16/50\n",
      "28/28 [==============================] - 18s 628ms/step - loss: 4.7692e-04 - accuracy: 1.0000 - val_loss: 4.1187 - val_accuracy: 0.2000\n",
      "Epoch 17/50\n",
      "28/28 [==============================] - 18s 629ms/step - loss: 5.4529e-04 - accuracy: 1.0000 - val_loss: 4.1238 - val_accuracy: 0.2000\n",
      "Epoch 18/50\n",
      "28/28 [==============================] - 18s 629ms/step - loss: 3.5873e-04 - accuracy: 1.0000 - val_loss: 4.1347 - val_accuracy: 0.2000\n",
      "Epoch 19/50\n",
      "28/28 [==============================] - 17s 621ms/step - loss: 3.6059e-04 - accuracy: 1.0000 - val_loss: 4.1413 - val_accuracy: 0.2000\n",
      "Epoch 20/50\n",
      "28/28 [==============================] - 17s 621ms/step - loss: 4.0130e-04 - accuracy: 1.0000 - val_loss: 4.1709 - val_accuracy: 0.2000\n",
      "Epoch 21/50\n",
      "28/28 [==============================] - 17s 608ms/step - loss: 3.1466e-04 - accuracy: 1.0000 - val_loss: 4.1844 - val_accuracy: 0.2000\n",
      "Epoch 22/50\n",
      "28/28 [==============================] - 17s 617ms/step - loss: 2.7062e-04 - accuracy: 1.0000 - val_loss: 4.1870 - val_accuracy: 0.2000\n",
      "Epoch 23/50\n",
      "28/28 [==============================] - 17s 619ms/step - loss: 2.3419e-04 - accuracy: 1.0000 - val_loss: 4.1963 - val_accuracy: 0.2000\n",
      "Epoch 24/50\n",
      "28/28 [==============================] - 18s 628ms/step - loss: 2.3019e-04 - accuracy: 1.0000 - val_loss: 4.2155 - val_accuracy: 0.2000\n",
      "Epoch 25/50\n",
      "28/28 [==============================] - 18s 635ms/step - loss: 2.3844e-04 - accuracy: 1.0000 - val_loss: 4.2022 - val_accuracy: 0.2000\n",
      "Epoch 26/50\n",
      "28/28 [==============================] - 19s 683ms/step - loss: 1.8366e-04 - accuracy: 1.0000 - val_loss: 4.2081 - val_accuracy: 0.2000\n",
      "Epoch 27/50\n",
      "28/28 [==============================] - 19s 696ms/step - loss: 1.8349e-04 - accuracy: 1.0000 - val_loss: 4.2210 - val_accuracy: 0.2000\n",
      "Epoch 28/50\n",
      "28/28 [==============================] - 18s 629ms/step - loss: 1.6243e-04 - accuracy: 1.0000 - val_loss: 4.2286 - val_accuracy: 0.2000\n",
      "Epoch 29/50\n",
      "28/28 [==============================] - 17s 619ms/step - loss: 1.4461e-04 - accuracy: 1.0000 - val_loss: 4.2315 - val_accuracy: 0.2000\n",
      "Epoch 30/50\n",
      "28/28 [==============================] - 17s 619ms/step - loss: 1.4596e-04 - accuracy: 1.0000 - val_loss: 4.2508 - val_accuracy: 0.2000\n",
      "Epoch 31/50\n",
      "28/28 [==============================] - 18s 629ms/step - loss: 2.1904e-04 - accuracy: 1.0000 - val_loss: 4.2530 - val_accuracy: 0.2000\n",
      "Epoch 32/50\n",
      "28/28 [==============================] - 18s 635ms/step - loss: 1.5649e-04 - accuracy: 1.0000 - val_loss: 4.2774 - val_accuracy: 0.2000\n",
      "Epoch 33/50\n",
      "28/28 [==============================] - 17s 626ms/step - loss: 1.1216e-04 - accuracy: 1.0000 - val_loss: 4.2831 - val_accuracy: 0.2000\n",
      "Epoch 34/50\n",
      "28/28 [==============================] - 18s 631ms/step - loss: 1.3418e-04 - accuracy: 1.0000 - val_loss: 4.3090 - val_accuracy: 0.2000\n",
      "Epoch 35/50\n",
      "28/28 [==============================] - 18s 632ms/step - loss: 9.8947e-05 - accuracy: 1.0000 - val_loss: 4.3188 - val_accuracy: 0.2000\n",
      "Epoch 36/50\n",
      "28/28 [==============================] - 18s 641ms/step - loss: 1.0590e-04 - accuracy: 1.0000 - val_loss: 4.3243 - val_accuracy: 0.2000\n",
      "Epoch 37/50\n",
      "28/28 [==============================] - 17s 624ms/step - loss: 8.3761e-05 - accuracy: 1.0000 - val_loss: 4.3267 - val_accuracy: 0.2000\n",
      "Epoch 38/50\n",
      "28/28 [==============================] - 18s 629ms/step - loss: 7.9267e-05 - accuracy: 1.0000 - val_loss: 4.3287 - val_accuracy: 0.2000\n",
      "Epoch 39/50\n",
      "28/28 [==============================] - 18s 633ms/step - loss: 9.0200e-05 - accuracy: 1.0000 - val_loss: 4.3310 - val_accuracy: 0.2000\n",
      "Epoch 40/50\n",
      "28/28 [==============================] - 18s 634ms/step - loss: 7.7506e-05 - accuracy: 1.0000 - val_loss: 4.3378 - val_accuracy: 0.2000\n",
      "Epoch 41/50\n",
      "28/28 [==============================] - 18s 634ms/step - loss: 8.9007e-05 - accuracy: 1.0000 - val_loss: 4.3528 - val_accuracy: 0.2000\n",
      "Epoch 42/50\n",
      "28/28 [==============================] - 18s 645ms/step - loss: 7.5362e-05 - accuracy: 1.0000 - val_loss: 4.3602 - val_accuracy: 0.2000\n",
      "Epoch 43/50\n",
      "28/28 [==============================] - 18s 643ms/step - loss: 8.0314e-05 - accuracy: 1.0000 - val_loss: 4.3661 - val_accuracy: 0.2182\n",
      "Epoch 44/50\n",
      "28/28 [==============================] - 18s 647ms/step - loss: 7.1503e-05 - accuracy: 1.0000 - val_loss: 4.3794 - val_accuracy: 0.2182\n",
      "Epoch 45/50\n",
      "28/28 [==============================] - 18s 634ms/step - loss: 6.5545e-05 - accuracy: 1.0000 - val_loss: 4.3993 - val_accuracy: 0.2182\n",
      "Epoch 46/50\n",
      "28/28 [==============================] - 18s 633ms/step - loss: 6.1063e-05 - accuracy: 1.0000 - val_loss: 4.3972 - val_accuracy: 0.2182\n",
      "Epoch 47/50\n",
      "28/28 [==============================] - 18s 637ms/step - loss: 5.8561e-05 - accuracy: 1.0000 - val_loss: 4.3991 - val_accuracy: 0.2182\n",
      "Epoch 48/50\n",
      "28/28 [==============================] - 18s 643ms/step - loss: 5.6161e-05 - accuracy: 1.0000 - val_loss: 4.3921 - val_accuracy: 0.2182\n",
      "Epoch 49/50\n",
      "28/28 [==============================] - 18s 636ms/step - loss: 5.0874e-05 - accuracy: 1.0000 - val_loss: 4.3916 - val_accuracy: 0.2182\n",
      "Epoch 50/50\n",
      "28/28 [==============================] - 18s 635ms/step - loss: 5.8803e-05 - accuracy: 1.0000 - val_loss: 4.4216 - val_accuracy: 0.2182\n"
     ]
    }
   ],
   "source": [
    "#model is being trained with 50 epochs and 16 batchSize using GPU\n",
    "#A small batchSize value is being chosen to prevent GPU memory problem\n",
    "#Large batchSize reduce training time while also generally providing better results\n",
    "with tf.device(myGPU):\n",
    "    trainingHistory = model.fit(\n",
    "        FitSequence(trainingX, trainingY, 16),\n",
    "        epochs = 50,\n",
    "        validation_data = FitSequence(validationX, validationY, 16)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Loss Chart is being drawn\n",
    "\n",
    "#Chart Values\n",
    "plt.plot(trainingHistory.history['loss'])\n",
    "plt.plot(trainingHistory.history['val_loss'])\n",
    "\n",
    "#Chart Tittle\n",
    "plt.title('Model Loss Chart')\n",
    "\n",
    "#Chart Labels\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "#Chart Lines\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "\n",
    "#Show Method\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Loss Chart is being drawn\n",
    "\n",
    "#Chart Values\n",
    "plt.plot(trainingHistory.history['accuracy'])\n",
    "plt.plot(trainingHistory.history['val_accuracy'])\n",
    "\n",
    "#Chart Tittle\n",
    "plt.title('model accuracy')\n",
    "\n",
    "#Chart Labels\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "#Chart Lines\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "\n",
    "#Show Method\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PersonID</th>\n",
       "      <th>ImageBGR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72</td>\n",
       "      <td>[[[0, 0, 3], [0, 0, 3], [0, 0, 3], [0, 0, 3], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>[[[0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>[[[76, 11, 3], [76, 11, 3], [77, 11, 3], [78, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>[[[150, 165, 251], [148, 164, 247], [150, 164,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>[[[48, 69, 77], [49, 70, 78], [49, 68, 76], [4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>88</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>97</td>\n",
       "      <td>[[[169, 168, 172], [168, 167, 171], [168, 167,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>87</td>\n",
       "      <td>[[[82, 82, 96], [82, 82, 95], [83, 81, 93], [8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>105</td>\n",
       "      <td>[[[0, 5, 74], [0, 6, 72], [1, 6, 71], [2, 6, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>67</td>\n",
       "      <td>[[[0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>76</td>\n",
       "      <td>[[[18, 14, 3], [18, 14, 3], [19, 16, 2], [19, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>95</td>\n",
       "      <td>[[[9, 52, 101], [12, 55, 104], [13, 56, 105], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>108</td>\n",
       "      <td>[[[1, 1, 1], [2, 1, 1], [11, 10, 10], [13, 10,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>46</td>\n",
       "      <td>[[[209, 209, 209], [209, 209, 209], [209, 209,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>110</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>51</td>\n",
       "      <td>[[[60, 92, 87], [59, 91, 86], [60, 92, 87], [6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>57</td>\n",
       "      <td>[[[69, 77, 84], [71, 79, 86], [73, 81, 88], [7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>[[[50, 75, 107], [57, 82, 114], [62, 90, 121],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>85</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>60</td>\n",
       "      <td>[[[57, 62, 63], [58, 64, 63], [62, 67, 64], [6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>78</td>\n",
       "      <td>[[[0, 3, 8], [0, 4, 9], [0, 5, 10], [1, 6, 11]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>31</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>38</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>80</td>\n",
       "      <td>[[[156, 157, 153], [159, 159, 155], [163, 162,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>47</td>\n",
       "      <td>[[[21, 33, 45], [24, 37, 49], [26, 40, 52], [2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>22</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>55</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>92</td>\n",
       "      <td>[[[0, 2, 0], [0, 2, 0], [1, 0, 0], [4, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>100</td>\n",
       "      <td>[[[175, 189, 238], [186, 200, 246], [206, 220,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>14</td>\n",
       "      <td>[[[2, 0, 1], [0, 1, 0], [3, 3, 0], [70, 50, 41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>84</td>\n",
       "      <td>[[[2, 0, 1], [2, 0, 1], [2, 0, 1], [2, 0, 1], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>70</td>\n",
       "      <td>[[[0, 3, 0], [0, 3, 0], [0, 3, 0], [0, 2, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>79</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>[[[91, 126, 114], [87, 121, 110], [83, 117, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>28</td>\n",
       "      <td>[[[2, 0, 0], [2, 0, 0], [2, 0, 0], [2, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>91</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>90</td>\n",
       "      <td>[[[0, 0, 3], [0, 0, 3], [0, 0, 3], [0, 0, 2], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>13</td>\n",
       "      <td>[[[21, 85, 140], [12, 74, 128], [4, 65, 119], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>9</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>17</td>\n",
       "      <td>[[[115, 43, 25], [115, 43, 25], [112, 40, 22],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>49</td>\n",
       "      <td>[[[5, 0, 0], [5, 0, 0], [5, 0, 0], [5, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>[[[0, 2, 0], [1, 1, 0], [5, 0, 0], [9, 0, 2], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>48</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>86</td>\n",
       "      <td>[[[130, 198, 227], [120, 190, 221], [101, 171,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>4</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>26</td>\n",
       "      <td>[[[0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>52</td>\n",
       "      <td>[[[137, 83, 60], [140, 83, 61], [142, 83, 61],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>43</td>\n",
       "      <td>[[[7, 12, 11], [6, 11, 10], [6, 11, 10], [6, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>82</td>\n",
       "      <td>[[[161, 219, 225], [161, 219, 225], [164, 219,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>83</td>\n",
       "      <td>[[[0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>39</td>\n",
       "      <td>[[[0, 0, 3], [0, 0, 3], [0, 0, 3], [0, 0, 3], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>[[[51, 62, 59], [48, 57, 54], [39, 48, 45], [4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>41</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>15</td>\n",
       "      <td>[[[158, 255, 253], [157, 255, 253], [156, 255,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>58</td>\n",
       "      <td>[[[0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>106</td>\n",
       "      <td>[[[27, 86, 113], [31, 99, 129], [31, 114, 146]...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PersonID                                           ImageBGR\n",
       "0         72  [[[0, 0, 3], [0, 0, 3], [0, 0, 3], [0, 0, 3], ...\n",
       "1         37  [[[0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], ...\n",
       "2         21  [[[76, 11, 3], [76, 11, 3], [77, 11, 3], [78, ...\n",
       "3        104  [[[150, 165, 251], [148, 164, 247], [150, 164,...\n",
       "4         65  [[[48, 69, 77], [49, 70, 78], [49, 68, 76], [4...\n",
       "5         88  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "6         97  [[[169, 168, 172], [168, 167, 171], [168, 167,...\n",
       "7         87  [[[82, 82, 96], [82, 82, 95], [83, 81, 93], [8...\n",
       "8        105  [[[0, 5, 74], [0, 6, 72], [1, 6, 71], [2, 6, 7...\n",
       "9         67  [[[0, 2, 0], [0, 2, 0], [0, 2, 0], [0, 2, 0], ...\n",
       "10        76  [[[18, 14, 3], [18, 14, 3], [19, 16, 2], [19, ...\n",
       "11        95  [[[9, 52, 101], [12, 55, 104], [13, 56, 105], ...\n",
       "12       108  [[[1, 1, 1], [2, 1, 1], [11, 10, 10], [13, 10,...\n",
       "13        46  [[[209, 209, 209], [209, 209, 209], [209, 209,...\n",
       "14       110  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "15        51  [[[60, 92, 87], [59, 91, 86], [60, 92, 87], [6...\n",
       "16        57  [[[69, 77, 84], [71, 79, 86], [73, 81, 88], [7...\n",
       "17         3  [[[50, 75, 107], [57, 82, 114], [62, 90, 121],...\n",
       "18        85  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "19        60  [[[57, 62, 63], [58, 64, 63], [62, 67, 64], [6...\n",
       "20        78  [[[0, 3, 8], [0, 4, 9], [0, 5, 10], [1, 6, 11]...\n",
       "21        31  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "22        38  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "23         2  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "24        80  [[[156, 157, 153], [159, 159, 155], [163, 162,...\n",
       "25        47  [[[21, 33, 45], [24, 37, 49], [26, 40, 52], [2...\n",
       "26        22  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "27        55  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "28        92  [[[0, 2, 0], [0, 2, 0], [1, 0, 0], [4, 0, 0], ...\n",
       "29       100  [[[175, 189, 238], [186, 200, 246], [206, 220,...\n",
       "30        14  [[[2, 0, 1], [0, 1, 0], [3, 3, 0], [70, 50, 41...\n",
       "31        84  [[[2, 0, 1], [2, 0, 1], [2, 0, 1], [2, 0, 1], ...\n",
       "32        70  [[[0, 3, 0], [0, 3, 0], [0, 3, 0], [0, 2, 0], ...\n",
       "33        79  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "34        34  [[[91, 126, 114], [87, 121, 110], [83, 117, 10...\n",
       "35        28  [[[2, 0, 0], [2, 0, 0], [2, 0, 0], [2, 0, 0], ...\n",
       "36        91  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "37        90  [[[0, 0, 3], [0, 0, 3], [0, 0, 3], [0, 0, 2], ...\n",
       "38        13  [[[21, 85, 140], [12, 74, 128], [4, 65, 119], ...\n",
       "39         9  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "40        17  [[[115, 43, 25], [115, 43, 25], [112, 40, 22],...\n",
       "41        49  [[[5, 0, 0], [5, 0, 0], [5, 0, 0], [5, 0, 0], ...\n",
       "42        42  [[[0, 2, 0], [1, 1, 0], [5, 0, 0], [9, 0, 2], ...\n",
       "43        48  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "44        86  [[[130, 198, 227], [120, 190, 221], [101, 171,...\n",
       "45         4  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "46        26  [[[0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 0, 0], ...\n",
       "47        52  [[[137, 83, 60], [140, 83, 61], [142, 83, 61],...\n",
       "48        43  [[[7, 12, 11], [6, 11, 10], [6, 11, 10], [6, 1...\n",
       "49        82  [[[161, 219, 225], [161, 219, 225], [164, 219,...\n",
       "50        83  [[[0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], ...\n",
       "51        39  [[[0, 0, 3], [0, 0, 3], [0, 0, 3], [0, 0, 3], ...\n",
       "52         1  [[[51, 62, 59], [48, 57, 54], [39, 48, 45], [4...\n",
       "53        41  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "54        15  [[[158, 255, 253], [157, 255, 253], [156, 255,...\n",
       "55        58  [[[0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], ...\n",
       "56       106  [[[27, 86, 113], [31, 99, 129], [31, 114, 146]..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FullPhoto Test data is being read from pkl file\n",
    "testDf = pd.read_pickle(\"../../../Data/FirstQuarter/FullPhoto/Test.pkl\")\n",
    "testDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 224, 224, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testX is being extracted from testDf as wanted shape\n",
    "#Pixel values are being converted  to the [-1, 1] range with the simplest method (pixel / 127.5 - 1)\n",
    "testX = (np.array(testDf.ImageBGR.values.tolist()) / 127.5) - 1\n",
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testY is being extracted from testDf as wanted shape\n",
    "testY = np.array(testDf.PersonID.values.tolist()).reshape((-1,1))\n",
    "testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 9s 3s/step - loss: 3.9306 - accuracy: 0.2105\n"
     ]
    }
   ],
   "source": [
    "#Model is being evaluated with test data\n",
    "#Sequence class is being also used for evaluation to convert test data into the same format as training data\n",
    "testResult = model.evaluate(FitSequence(testX, testY, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 3.9305968284606934\n"
     ]
    }
   ],
   "source": [
    "#Test Loss is being Printed\n",
    "print('Test Loss: ' + str(testResult[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.21052631735801697\n"
     ]
    }
   ],
   "source": [
    "#Test Accuracy is being Printed\n",
    "print('Test Accuracy: ' + str(testResult[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training5 Inference\n",
    "\n",
    "By looking at the charts, it can be said that training results in overfitting.\n",
    "\n",
    "A similar architecture was trained with same data in the Training1 notebook file without the Transfer Learning method.\n",
    "\n",
    "Although the results are much better than those in the Training1 notebook file, a success of about 20% on the Validation data and about 100% on the Training data indicates overfitting.\n",
    "\n",
    "In this case, it can be said that overfitting is caused by too few images for each person.\n",
    "\n",
    "This example clearly demonstrates the power of Transfer Learning.\n",
    "\n",
    "Performance can be improved by trying Hyperparameter Optimization methods.\n",
    "\n",
    "See https://en.wikipedia.org/wiki/Hyperparameter_optimization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py39AI",
   "language": "python",
   "name": "py39ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
